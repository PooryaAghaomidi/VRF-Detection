{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b16664-69d7-4eb7-9ae8-dfe2648f620c",
   "metadata": {},
   "source": [
    "# *Configuration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b1f99b-7825-4941-a103-a226bee1c2ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "399783283c0f335b",
    "outputId": "c161d579-2ba3-44c2-905a-2dee8b144ce4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938b99f-d5ec-489d-88b2-b95f44b2dcc6",
   "metadata": {},
   "source": [
    "# *Import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.exposure import equalize_adapthist\n",
    "from scipy.ndimage import rotate, gaussian_filter, map_coordinates, zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c6537-34c7-4a9d-9482-ed27668da197",
   "metadata": {},
   "source": [
    "# *Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hjuoTwNA8cRt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjuoTwNA8cRt",
    "outputId": "883c991c-b96e-40ce-d52d-b82890517b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  540\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/content/drive/MyDrive/Teeth/Final\"\n",
    "files = os.listdir(data_path)\n",
    "print(\"Dataset size: \", len(files))\n",
    "\n",
    "val_codes_primary = [\"u7\", \"v8\", \"w9\", \"x10\", \"y11\", \"z12\", \"a61\", \"b62\", \"c63\", \"d64\", \"e65\", \"f66\", \"a67\", \"b68\", \"c69\", \"d70\", \"e71\", \"f72\"]\n",
    "val_codes_label_based = [\"a73\", \"b74\", \"c75\", \"d76\", \"e77\", \"f78\"]\n",
    "\n",
    "val_data = []\n",
    "train_data = []\n",
    "\n",
    "for file_name in os.listdir(data_path):\n",
    "    parts = file_name.split(\"_\")\n",
    "    binary_label = parts[1]\n",
    "    code = parts[2].split(\"-\")[0]\n",
    "\n",
    "    if code in val_codes_primary or (code in val_codes_label_based and binary_label == \"1\"):\n",
    "        val_data.append(file_name)\n",
    "    else:\n",
    "        train_data.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e64223",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for file in train_data:\n",
    "    x = np.load(os.path.join(\"/content/drive/MyDrive/Teeth/Final\", file))[\"arr_0\"]\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "    x_train.append(x)\n",
    "    \n",
    "    y_train.append(int(file[5]))\n",
    "\n",
    "x_train  = np.expand_dims(np.array(x_train, dtype=np.float32), axis=-1)\n",
    "y_train  = np.array(y_train, dtype=np.int32)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "np.savez_compressed(f\"/content/drive/MyDrive/Init/Train.npz\", x=x_train, y=y_train)\n",
    "print(\"Train has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for file in train_data:\n",
    "    x = np.load(os.path.join(\"/content/drive/MyDrive/Teeth/Final\", file))[\"arr_0\"]\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "    x_val.append(x)\n",
    "    \n",
    "    y_val.append(int(file[5]))\n",
    "\n",
    "x_val  = np.expand_dims(np.array(x_val, dtype=np.float32), axis=-1)\n",
    "y_val  = np.array(y_val, dtype=np.int32)\n",
    "x_val, y_val = shuffle(x_val, y_val, random_state=42)\n",
    "\n",
    "np.savez_compressed(f\"/content/drive/MyDrive/Init/Validation.npz\", x=x_val, y=y_val)\n",
    "print(\"Validation has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eec745",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for file in os.listdir(\"/content/drive/MyDrive/Teeth/Final_Test\"):\n",
    "    x = np.load(os.path.join(\"/content/drive/MyDrive/Teeth/Final_Test\", file))[\"arr_0\"]\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "    x_test.append(x)\n",
    "    \n",
    "    last_part = file.split('_')[-1]\n",
    "    y_test.append(int(last_part.split('.')[0]))\n",
    "\n",
    "x_test  = np.expand_dims(np.array(x_test, dtype=np.float32), axis=-1)\n",
    "y_test  = np.array(y_test, dtype=np.int32)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=42)\n",
    "\n",
    "np.savez_compressed(f\"/content/drive/MyDrive/Init/Test.npz\", x=x_test, y=y_test)\n",
    "print(\"Test has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    with np.load(\"/content/drive/MyDrive/Teeth/Init/Train.npz\") as data:\n",
    "        x_train = data['x']\n",
    "        y_train = data['y']\n",
    "\n",
    "    with np.load(\"/content/drive/MyDrive/Teeth/Init/Validation.npz\") as data:\n",
    "        x_val = data['x']\n",
    "        y_val = data['y']\n",
    "\n",
    "    with np.load(\"/content/drive/MyDrive/Teeth/Init/Test.npz\") as data:\n",
    "        x_test = data['x'].astype(np.float32)\n",
    "        y_test = data['y']\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056c8f2",
   "metadata": {},
   "source": [
    "# *Fix Padding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding_borders(x, tol=1e-3):\n",
    "    def find_padding_extent(arr, axis):\n",
    "        size = arr.shape[axis]\n",
    "        start, end = 0, size\n",
    "\n",
    "        # Start border\n",
    "        for i in range(size):\n",
    "            sl = np.take(arr, indices=i, axis=axis)\n",
    "            if np.allclose(sl, sl.flat[0], atol=tol):\n",
    "                start += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # End border\n",
    "        for i in reversed(range(size)):\n",
    "            sl = np.take(arr, indices=i, axis=axis)\n",
    "            if np.allclose(sl, sl.flat[0], atol=tol):\n",
    "                end -= 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return start, end\n",
    "\n",
    "    x_clean = np.copy(x)\n",
    "\n",
    "    for idx in tqdm(range(x.shape[0])):\n",
    "        sample = x_clean[idx, :, :, :, 0]\n",
    "\n",
    "        # Find borders in each axis\n",
    "        d_start, d_end = find_padding_extent(sample, 0)\n",
    "        h_start, h_end = find_padding_extent(sample, 1)\n",
    "        w_start, w_end = find_padding_extent(sample, 2)\n",
    "\n",
    "        # Set paddings to zero\n",
    "        sample[:d_start, :, :] = 0\n",
    "        sample[d_end:, :, :] = 0\n",
    "        sample[:, :h_start, :] = 0\n",
    "        sample[:, h_end:, :] = 0\n",
    "        sample[:, :, :w_start] = 0\n",
    "        sample[:, :, w_end:] = 0\n",
    "\n",
    "        x_clean[idx, :, :, :, 0] = sample\n",
    "\n",
    "    return x_clean\n",
    "\n",
    "\n",
    "x_train = remove_padding_borders(x_train)\n",
    "x_val = remove_padding_borders(x_val)\n",
    "x_test = remove_padding_borders(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3f49a",
   "metadata": {},
   "source": [
    "# *Prepare Train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SmPV07AIqQ5y",
   "metadata": {
    "id": "SmPV07AIqQ5y"
   },
   "outputs": [],
   "source": [
    "def elastic_deformation(data, alpha=15, sigma=3):\n",
    "    shape = data.shape\n",
    "    dx = gaussian_filter(np.random.randn(*shape), sigma) * alpha\n",
    "    dy = gaussian_filter(np.random.randn(*shape), sigma) * alpha\n",
    "    dz = gaussian_filter(np.random.randn(*shape), sigma) * alpha\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "    indices = (x + dx, y + dy, z + dz)\n",
    "    return map_coordinates(data, indices, order=1, mode='reflect')\n",
    "\n",
    "def random_rotation(data, max_angle=10):\n",
    "    angle = np.random.uniform(-max_angle, max_angle)\n",
    "    axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "    return rotate(data, angle, axes=axes, reshape=False, mode='nearest')\n",
    "\n",
    "def random_flip(data):\n",
    "    if np.random.rand() > 0.5:\n",
    "        data = np.flip(data, axis=0)\n",
    "    if np.random.rand() > 0.5:\n",
    "        data = np.flip(data, axis=1)\n",
    "    if np.random.rand() > 0.5:\n",
    "        data = np.flip(data, axis=2)\n",
    "    return data\n",
    "\n",
    "def add_noise(data, min_scale=0.05, max_scale=0.15):\n",
    "    scale = np.random.uniform(min_scale, max_scale)\n",
    "    noise = np.random.normal(loc=0.0, scale=scale, size=data.shape)\n",
    "    return data + noise\n",
    "\n",
    "def random_zoom(data, zoom_range=(1.1, 1.5)):\n",
    "    zoom_factor = np.random.uniform(*zoom_range)\n",
    "    zoomed = zoom(data, zoom_factor, order=1, mode='nearest')\n",
    "\n",
    "    original_shape = data.shape\n",
    "    zoomed_shape = zoomed.shape\n",
    "    crop_slices = tuple(\n",
    "        slice((z - o) // 2, (z - o) // 2 + o) if z > o else slice(0, o)\n",
    "        for o, z in zip(original_shape, zoomed_shape)\n",
    "    )\n",
    "    return zoomed[crop_slices]\n",
    "\n",
    "def apply_augmentations(data):\n",
    "    augmentations = [random_rotation,\n",
    "                     random_flip,\n",
    "                     add_noise,\n",
    "                     random_zoom,\n",
    "                     elastic_deformation]\n",
    "\n",
    "    random.shuffle(augmentations)\n",
    "    augment_set1 = augmentations[:3]\n",
    "    augment_set2 = augmentations[3:]\n",
    "\n",
    "    augmented1 = data.copy()\n",
    "    for augment in augment_set1:\n",
    "        augmented1 = augment(augmented1)\n",
    "\n",
    "    augmented2 = data.copy()\n",
    "    for augment in augment_set2:\n",
    "        augmented2 = augment(augmented2)\n",
    "\n",
    "    return data, augmented1, augmented2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_background(x, threshold=0.3):\n",
    "    x_clean = np.copy(x)\n",
    "    x_clean[np.abs(x_clean) < threshold] = 0\n",
    "    return x_clean\n",
    "\n",
    "def local_contrast_enhancement(data, clip_limit=0.03):\n",
    "    return equalize_adapthist(data, clip_limit=clip_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xwQV3gSiCegH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwQV3gSiCegH",
    "outputId": "add609cb-3cfa-4038-bbac-69a8d2c89073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [04:39<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-augmented has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:15<00:00, 28.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:04<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation has been saved!\n"
     ]
    }
   ],
   "source": [
    "def process_files(x_init, y_init):\n",
    "    X, y = [], []\n",
    "\n",
    "    x_init_rm = threshold_background(x_init)\n",
    "\n",
    "    for idx in tqdm(range(x_init.shape[0])):\n",
    "        enhanced = local_contrast_enhancement(x_init_rm[idx, 20:120, :, :, 0])\n",
    "        original, augmented1, augmented2 = apply_augmentations(enhanced)\n",
    "\n",
    "        original = original[..., np.newaxis]\n",
    "        augmented1 = augmented1[..., np.newaxis]\n",
    "        augmented2 = augmented2[..., np.newaxis]\n",
    "\n",
    "        original = (original - np.min(original)) / (np.max(original) - np.min(original))\n",
    "        augmented1 = (augmented1 - np.min(augmented1)) / (np.max(augmented1) - np.min(augmented1))\n",
    "        augmented2 = (augmented2 - np.min(augmented2)) / (np.max(augmented2) - np.min(augmented2))\n",
    "\n",
    "        X.extend([original, augmented1, augmented2])\n",
    "\n",
    "        label = int(y_init[idx])\n",
    "        y.extend([label, label, label])\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    np.savez_compressed(f\"/content/drive/MyDrive/Teeth/Final/train.npz\", x=X, y=y)\n",
    "    print(f\"Train set has been saved!\")\n",
    "\n",
    "\n",
    "process_files(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cafca",
   "metadata": {},
   "source": [
    "# *Prepare Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abe17e-5f36-4278-9b62-858568feef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eval_files(x_init, y_init, file_name):\n",
    "    X, y = [], []\n",
    "\n",
    "    x_init_rm = threshold_background(x_init)\n",
    "\n",
    "    for idx in tqdm(range(x_init.shape[0])):\n",
    "        enhanced = local_contrast_enhancement(x_init_rm[idx, 20:120, :, :, 0])\n",
    "\n",
    "        original = enhanced[..., np.newaxis]\n",
    "        original = (original - np.min(original)) / (np.max(original) - np.min(original))\n",
    "\n",
    "        X.append(original)\n",
    "\n",
    "        label = int(y_init[idx])\n",
    "        y.append(label)\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    np.savez_compressed(f\"/content/drive/MyDrive/Teeth/Final/{file_name}.npz\", x=X, y=y)\n",
    "    print(f\"{file_name} set has been saved!\")\n",
    "\n",
    "\n",
    "process_eval_files(x_test, y_test, \"Test\")\n",
    "process_eval_files(x_val, y_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383645f",
   "metadata": {},
   "source": [
    "# *Evaluate Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ea34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    with np.load(\"/content/drive/MyDrive/Teeth/Final/train.npz\") as data:\n",
    "        x_train = data['x']\n",
    "        y_train = data['y']\n",
    "\n",
    "    with np.load(\"/content/drive/MyDrive/Teeth/Final/Validation.npz\") as data:\n",
    "        x_val = data['x']\n",
    "        y_val = data['y']\n",
    "\n",
    "    with np.load(\"/content/drive/MyDrive/Teeth/Final/Test.npz\") as data:\n",
    "        x_test = data['x'].astype(np.float32)\n",
    "        y_test = data['y']\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9630ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Shape\n",
    "print(\"Shapes:\")\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"x_val:\", x_val.shape)\n",
    "print(\"x_test:\", x_test.shape)\n",
    "\n",
    "# 2. Label Balance\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(\"Train:\", Counter(y_train))\n",
    "print(\"Validation:\", Counter(y_val))\n",
    "print(\"Test:\", Counter(y_test))\n",
    "\n",
    "# 3. Normalization Check\n",
    "def check_normalization(x, name):\n",
    "    print(f\"\\n{name} stats:\")\n",
    "    print(\"Min:\", np.min(x))\n",
    "    print(\"Max:\", np.max(x))\n",
    "    print(\"Mean:\", np.mean(x))\n",
    "    print(\"Std:\", np.std(x))\n",
    "\n",
    "check_normalization(x_train, \"Train\")\n",
    "check_normalization(x_val, \"Validation\")\n",
    "check_normalization(x_test, \"Test\")\n",
    "\n",
    "# 4. Visualization - Hint-based plot\n",
    "def plot_dataset(dataset):\n",
    "  for i in range(0, 90, 10):\n",
    "    plt.imshow(dataset[i, :, 25, :, 0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "plot_dataset(x_train)\n",
    "plot_dataset(x_test)\n",
    "plot_dataset(x_val)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
